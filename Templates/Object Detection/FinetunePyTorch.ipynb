{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# About\n",
        "- To simplify the template, this line assumes we are working with local pickled data\n",
        "- All methods will assume Pandas dataframe is being used\n",
        "- Other loading examples can be found at the bottom of this template\n",
        "\n",
        "- For Deep Learning (Object Detection Training), it is best to work with cuda\n",
        "- As such this template assumes that you are working on cuda device with PyTorch Tensor objects\n",
        "\n",
        "<!-- TABLE OF CONTENTS -->\n",
        "<details>\n",
        "  <summary>Table of Contents</summary>\n",
        "  <ol>\n",
        "    <li>\n",
        "      <a href=\"#pandas-load\">About The Project</a>\n",
        "    </li>\n",
        "    <li>\n",
        "      <a href=\"#getting-started\">Getting Started</a>\n",
        "    </li>\n",
        "    <li><a href=\"#contact\">Contact</a></li>\n",
        "  </ol>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivvd464JS8rh"
      },
      "source": [
        "# Starter Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VTbdLZKS3VK"
      },
      "outputs": [],
      "source": [
        "# Model Building\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.models import detection\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "# Data Extraction\n",
        "from PIL import Image # Image editing\n",
        "import io\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Data Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Testing\n",
        "import time\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Load Dataset\n",
        "\n",
        "## Pandas Load\n",
        "```python\n",
        "df_train = pd.read_pickle('PickledDataset.pkl')\n",
        "```\n",
        "\n",
        "## HuggingFace Load\n",
        "```python\n",
        "data_files = {\"train\": \"train*\", \"test\": \"test*\"}\n",
        "ds_train = load_dataset(\"parquet\", data_dir=\"C:\\\\Users\\\\bjorn\\\\mtg-detection\\\\data\\\\\", data_files=data_files, split=\"train[:20%]\")\n",
        "ds_train = ds_train.with_format(\"torch\", device=device)\n",
        "```\n",
        "\n",
        "## XML Load\n",
        "```python\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocess Metadata to Determine Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "It can be safe and easy to hardcode the number of classes\n",
        "when the dataset is well regulated and has clear documentation.\n",
        "Otherwise, it is advised to iterate over your dataset's metadata\n",
        "in order to confirm the number of classes and to initialize a dictionary\n",
        "to make class/label encoding easier in future processes.\n",
        "\n",
        "Remember: The number of classes is equal to the known classes + 1 for background\n",
        "which signifies \"no object\". This extra background class should be labeled as 0.\n",
        "\n",
        "The first step is to iterate over all available data to create a dictionary which maps classes from their original format (String, JSON, etc.)\\\n",
        "to a number encoding. This also allows us to determine our total number of classes which is equal to the known classes + 1 for background\\\n",
        "which signifies \"no object\". This extra background class should be labeled as 0.\n",
        "\n",
        "\"\"\"\n",
        "# Create numpy array of all unique labels\n",
        "unique_classes = df_train['metadata'].unique()\n",
        "\n",
        "# Create a label dictionary \n",
        "label_dict = {}\n",
        "i = 1 # Start at 1 because 0 is reserved for background objects\n",
        "for label in unique_classes:\n",
        "    label_dict[label] = i\n",
        "    i += 1\n",
        "\n",
        "number_of_classes = unique_classes.size + 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQYMm3E50IQN"
      },
      "source": [
        "# Set Device type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1vtzmHcz8qm",
        "outputId": "d45a4a38-744b-46b3-b21b-79ee5a2642ea"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device) # Double check that you are connected to the desired device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Switch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize a dictionary containing torchvision models to simplify testing a variety of training approaches\n",
        "models = {\n",
        "\t\"frcnn-resnet\": detection.fasterrcnn_resnet50_fpn,\n",
        "    \"frcnn-mobilenet\": detection.fasterrcnn_mobilenet_v3_large_320_fpn,\n",
        "}\n",
        "\n",
        "# Load the model and set it to evaluation mode\n",
        "model = models[\"frcnn-mobilenet\"](weights=\"DEFAULT\").to(device)\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, number_of_classes)\n",
        "\n",
        "# Insert load\n",
        "model.load_state_dict(torch.load('CardWeights.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Helper function to retrieve object data from dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Retrieves labels/bboxes and reformats image data from binary to torch tensors\n",
        "# Returns target: a dict of bboxes and labels; imgs: tuple of torch tensor images\n",
        "def generate_target(object):\n",
        "\n",
        "    # Bounding boxes for objects\n",
        "    # In pytorch, the input should be [xmin, ymin, xmax, ymax]\n",
        "    boxes = object['annotation']\n",
        "    labels = torch.ones(len(object['annotation'])) # All objects are of class \"Card\" / \"1\"\n",
        "    boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "    labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "    # Convert image from Byte to Tensor\n",
        "    img = Image.open(io.BytesIO(object['image'])).convert(\"RGB\")\n",
        "    data_transform = transforms.Compose([transforms.PILToTensor(), transforms.ConvertImageDtype(torch.float),])\n",
        "    img = data_transform(img).to(device)\n",
        "\n",
        "    # Annotation is in dictionary format\n",
        "    # Innate labels, bboxes and classifier (card vs. background)\n",
        "    target = {}\n",
        "    target[\"boxes\"] = boxes.to(device)\n",
        "    target[\"labels\"] = labels.to(device)\n",
        "\n",
        "    return target, img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bgz-odCudbl"
      },
      "source": [
        "# CREATE DATALOADER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifds5BAFiI_i"
      },
      "source": [
        "## Create collate function for DataLoader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "gWc9e6GciEaP"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "  return tuple(zip(*batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create custom map-style dataset to work with pickled pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, dataframe):\n",
        "        self.df = dataframe\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df.index)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        target, image = generate_target(self.df.loc[idx])\n",
        "        return target, image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwgcfpzIwq34"
      },
      "source": [
        "## Create train and validation DataLoader() objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TK-w284UbymJ"
      },
      "outputs": [],
      "source": [
        "# Test various batch sizes, higher batch = more memory usage but faster\n",
        "# If memory usage too high, then model trains slower and batch size must be reduced (idk where this point is)\n",
        "train_dl = torch.utils.data.DataLoader(dataset=CustomImageDataset(df_train),\n",
        "                                          batch_size=8,\n",
        "                                          collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Make Custom Faster RCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the pretrained Faster R-CNN model with a MobileNetV3 backbone\n",
        "model = fasterrcnn_mobilenet_v3_large_320_fpn(weights=\"DEFAULT\")\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, 2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lN8LXtKVF6Y"
      },
      "source": [
        "# Fine-tune Faster R-CNN model on our dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwMMwmgIzdZI"
      },
      "source": [
        "## Create optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0pfGz6jKVKbd"
      },
      "outputs": [],
      "source": [
        "# You can test other optimizers you find online, this is a standard one I use for Faster RCNN projects\n",
        "optimizer = torch.optim.SGD(model.parameters(),\n",
        "                            lr=0.005,\n",
        "                            momentum=0.9,\n",
        "                            weight_decay=0.0005)\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "                                               step_size=3,\n",
        "                                               gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# OPTIONAL if training a specific model further\n",
        "# model.load_state_dict(torch.load('CardWeights.pt'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewJ4lrmu0Pjf"
      },
      "source": [
        "## Fine-tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDFF3O6d0Hyu",
        "outputId": "b6058f76-b706-4de1-c533-c2dbbe21ea25"
      },
      "outputs": [],
      "source": [
        "model.to(device)\n",
        "num_epochs = 100\n",
        "len_dataloader = len(train_dl)\n",
        "e_num = 1\n",
        "losses_for_plot = []\n",
        "\n",
        "for epochs in range(num_epochs):\n",
        "  i = 1\n",
        "  model.train()\n",
        "  epoch_loss = 0\n",
        "  start = time.time()\n",
        "  for targets, imgs in tqdm(train_dl):\n",
        "\n",
        "    imgs = list(img.to(DEVICE) for img in imgs)\n",
        "    annotations = [{k: v.to(DEVICE) for k, v in t.items()} for t in targets]\n",
        "\n",
        "    loss_dict = model(imgs, annotations)\n",
        "    loss = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss\n",
        "\n",
        "  lr_scheduler.step()\n",
        "  print(f' Loss: {epoch_loss}, Time: {time.time() - start}, Epoch: {e_num}')\n",
        "  losses_for_plot.append(epoch_loss.item())\n",
        "  start = time.time()\n",
        "  e_num += 1\n",
        "  torch.save(model.state_dict(),'CardWeights1.pt') # Save after every Epoch\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualize Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(losses_for_plot)\n",
        "\n",
        "# Adding labels and title\n",
        "plt.title(\"Loss Per Epoch\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Additonal Approaches\n",
        "\n",
        "```python\n",
        "from sklearn import preprocessing \n",
        "\n",
        "label_encoder = preprocessing.LabelEncoder() \n",
        "df['species']= label_encoder.fit_transform(df['species']) \n",
        "df['species'].unique() \n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "y8mTLQCZbpyY"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
