{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# About\n",
        "This template is designed to efficiently preprocess large datasets, particularly images, with the goal of minimizing memory usage.\\\n",
        "In addition to images, metadata (bounding boxes, labels, etc.) can be preprocessed and converted to the desired format.\\\n",
        "All processed data is then stored in a Pandas DataFrame and saved as a .pkl file to preserve Python data structures.\n",
        "\n",
        "By preprocessing data in this manner, you can significantly reduce training time and enable the use of larger datasets on older or less powerful hardware.\\\n",
        "Additionally, this approach allows you to standardize input data so that model training code can be reused with various datasets.\n",
        "\n",
        "For examples of potential edge cases and solutions, refer to the section at the bottom of this file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivvd464JS8rh"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9VTbdLZKS3VK"
      },
      "outputs": [],
      "source": [
        "# Data Extraction\n",
        "from PIL import Image\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "# QoL\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create your Preprocessing class\n",
        "- Initialize your dataframe with desired columns such as 'images', 'annotations', 'metadata'\n",
        "- Load in your dataset\n",
        "- Create methods to transform data for each of the desired columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Preprocess():\n",
        "\n",
        "    def __init__(self, DESIRED_IMAGE_SIZE=(400, 400), DESIRED_FILE_NAME='transformed_data.pkl'):\n",
        "        self.dataframe = pd.DataFrame(columns = ['images', 'annotations', 'metadata'])\n",
        "        self.dataset = pd.read_pickle('pickleddata.pkl')\n",
        "        self.DESIRED_IMAGE_SIZE = DESIRED_IMAGE_SIZE\n",
        "        self.DESIRED_FILE_NAME = DESIRED_FILE_NAME\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "    Loads images and resizes them before converting them (back) to bytes data in JPEG format\n",
        "    This template method assumes that you are loading in a pickle file with images\n",
        "    saved as bytes data, however, it is commonly the case that you work with\n",
        "    saved JPEG or PNG images, in which case the the initial io.BytesIO is unecessary\n",
        "    \"\"\"\n",
        "    def transform_image(self, row):\n",
        "        img = Image.open(io.BytesIO(row['images'])).convert('RGB')\n",
        "        img = img.resize(self.DESIRED_IMAGE_SIZE, Image.Resampling.LANCZOS)\n",
        "        img_byte_arr = io.BytesIO()\n",
        "        img.save(img_byte_arr, format='JPEG')\n",
        "\n",
        "        return img_byte_arr.getvalue()\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Loops through all known bounding boxes in given image\n",
        "    Resizes bounding boxes to match desired image size\n",
        "    Assumes bbox data is already saved in Pascal VOC dataset format\n",
        "    \"\"\"\n",
        "    def transform_annotation(self, row):\n",
        "        boxes = []\n",
        "        for box in row['annotations']:\n",
        "            xmin = box[0] * self.DESIRED_IMAGE_SIZE[0]\n",
        "            ymin = box[1] * self.DESIRED_IMAGE_SIZE[1]\n",
        "            xmax = box[2] * self.DESIRED_IMAGE_SIZE[0]\n",
        "            ymax = box[3] * self.DESIRED_IMAGE_SIZE[1]\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "        return boxes\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Returns metadata as a number for labelling purposes\n",
        "    In this example there are 4 possible labels to come across\n",
        "    Method converts from string data to numbers\n",
        "    \"\"\"\n",
        "    def transform_metadata(self, row):\n",
        "        metadata = row['metadata']\n",
        "        if metadata is 'MaskWornCorrectly':\n",
        "            return 3\n",
        "        elif metadata is 'MaskWornIncorrectly':\n",
        "            return 2\n",
        "        elif metadata is 'NoMaskWorn':\n",
        "            return 1\n",
        "        else:\n",
        "            return 0 # label meaning 'background' or 'no object'\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Loops over all data and calls helper transform methods\n",
        "    Builds our dataframe using the transformed data\n",
        "    \"\"\"\n",
        "    def preprocess(self):\n",
        "        for idx, row in tqdm(self.dataset):\n",
        "            image = self.transform_image(row)\n",
        "            annotation = self.transform_annotation(row)\n",
        "            metadata = self.transform_metadata(row)\n",
        "\n",
        "            transformed_data = [image, annotation, metadata]\n",
        "            data_to_add = pd.DataFrame([transformed_data], columns=self.dataframe.columns)\n",
        "            self.dataframe = pd.concat([self.dataframe, data_to_add], ignore_index=True)\n",
        "        \n",
        "        return self.dataframe\n",
        "    \n",
        "\n",
        "    \"\"\"\n",
        "    Saves data as .pkl file \n",
        "    This maintains complex python data structures and data types, such as bytes\n",
        "    \"\"\"\n",
        "    def pickle_data(self):\n",
        "        self.dataframe.to_pickle(self.DESIRED_FILE_NAME)\n",
        "            "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Run the program"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DESIRED_IMAGE_SIZE = (360, 500)\n",
        "DESIRED_FILE_NAME = 'transformed_data.pkl'\n",
        "pp = Preprocess(DESIRED_IMAGE_SIZE, DESIRED_FILE_NAME)\n",
        "pp.preprocess()\n",
        "pp.pickle_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notable Scenarios:\n",
        "\n",
        "## Images and Metadata are separated\n",
        "- Create list of image file pathways and use idx value from .iterrows() to parse this list\n",
        "```python\n",
        "list(os.listdir(\"archive/train_images/\"))\n",
        "```\n",
        "\n",
        "---\n",
        "## Data stored in XML File\n",
        "- Use BeautifulSoup to parse through xml file data\n",
        "```python\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "with open(file) as f:\n",
        "        data = f.read()\n",
        "        soup = BeautifulSoup(data, 'xml')\n",
        "        objects = soup.find_all('object')\n",
        "\n",
        "        for obj in objects:\n",
        "            xmin = int(obj.find('xmin').text) # Example bounding box info\n",
        "            label = obj.find('name') # Example label info\n",
        "```\n",
        "\n",
        "---\n",
        "## Using HuggingFace\n",
        "- Load in desired data using load_dataset function\n",
        "- Loop through data like list, not like pandas dataframe\n",
        "```python\n",
        "# Example with parquet file\n",
        "data_files = {\"train\": \"train*\", \"test\": \"test*\"}\n",
        "dataset_train = load_dataset(\"parquet\", data_dir=\"C:\\\\Users\\\\User\\\\dataset_name\\\\data\\\\\", data_files=data_files, split=\"train[:20%]\")\n",
        "\n",
        "for element in dataset_train:\n",
        "    pass\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "y8mTLQCZbpyY"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
